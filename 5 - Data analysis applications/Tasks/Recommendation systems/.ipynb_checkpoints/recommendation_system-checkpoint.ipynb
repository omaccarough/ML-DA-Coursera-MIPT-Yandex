{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекоммендательные системы.\n",
    "### Описание задачи.\n",
    "Небольшой интернет-магазин попросил вас добавить ранжирование товаров в блок \"Смотрели ранее\" - в нем теперь надо показывать не последние просмотренные пользователем товары, а те товары из просмотренных, которые он наиболее вероятно купит. Качество вашего решения будет оцениваться по количеству покупок в сравнении с прошлым решением в ходе А/В теста, т.к. по доходу от продаж статзначимость будет достигаться дольше из-за разброса цен. Таким образом, ничего заранее не зная про корреляцию оффлайновых и онлайновых метрик качества, в начале проекта вы можете лишь постараться оптимизировать recall@k и precision@k.\n",
    "\n",
    "Это задание посвящено построению простых бейзлайнов для этой задачи: ранжирование просмотренных товаров по частоте просмотров и по частоте покупок. Эти бейзлайны, с одной стороны, могут помочь вам грубо оценить возможный эффект от ранжирования товаров в блоке - например, чтобы вписать какие-то числа в коммерческое предложение заказчику, а с другой стороны, могут оказаться самым хорошим вариантом, если данных очень мало (недостаточно для обучения даже простых моделей).\n",
    "### Входные данные.\n",
    "Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, 1,2,3,4; или 1,2,3,4;5,6.\n",
    "\n",
    "Гарантируется, что среди id купленных товаров все различные.\n",
    "### Важно.\n",
    " - Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    " - Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    " - Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    " - Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k.\n",
    " \n",
    "### Задание.\n",
    " - На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать) \n",
    "\n",
    "\n",
    " - Реализуйте два алгоритма рекомендаций:\n",
    "     1. сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "     2.  сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    " \n",
    "\n",
    " - Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие? Обратите внимание на различие качества на обучающей и тестовой выборке в случае рекомендаций по частотам покупки.\n",
    "\n",
    "Если частота одинаковая, то сортировать нужно по возрастанию момента просмотра (чем раньше появился в просмотренных, тем больше приоритет)\n",
    "\n",
    "### Дополнительные вопросы.\n",
    "\n",
    "Обратите внимание, что при сортировке по покупаемости возникает много товаров с одинаковым рангом - это означает, что значение метрик будет зависеть от того, как мы будем сортировать товары с одинаковым рангом. Попробуйте убедиться, что при изменении сортировки таких товаров recall@k меняется. Подумайте, как оценить минимальное и максимальное значение recall@k в зависимости от правила сортировки.\n",
    "Мы обучаемся и тестируемся на полных сессиях (в которых есть все просмотренные за сессию товары). Подумайте, почему полученная нами оценка качества рекомендаций в этом случае несколько завышена.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter, OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Reading train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coursera_sessions_train.txt', 'r') as f:\n",
    "    train_data = f.read().splitlines()\n",
    "\n",
    "with open('coursera_sessions_test.txt', 'r') as f:\n",
    "    test_data = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Creating a dictionary from a session and adding it to the sessions list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dicts(data):\n",
    "    new_list = []\n",
    "    for session in data:\n",
    "        viewed_id, purchased_id = session.split(';')\n",
    "        viewed_id = list(map(int, viewed_id.split(',')))\n",
    "        if len(purchased_id) > 0:\n",
    "            purchased_id = list(map(int, purchased_id.split(',')))\n",
    "        else:\n",
    "            purchased_id = []\n",
    "        new_list.append({'viewed': viewed_id, 'purchased': purchased_id})\n",
    "    return new_list\n",
    "\n",
    "train_sessions = list_of_dicts(train_data)\n",
    "test_sessions = list_of_dicts(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Creating counters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewed_counter = Counter()\n",
    "purchased_counter = Counter()\n",
    "\n",
    "for session in train_sessions:\n",
    "    viewed_counter.update(session['viewed'])\n",
    "    purchased_counter.update(session['purchased'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Creating lists of sessions where purchase was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptrain_sessions = []\n",
    "ptest_sessions = []\n",
    "\n",
    "for session in train_sessions:\n",
    "    if session['purchased'] != []:\n",
    "        ptrain_sessions.append(session)\n",
    "\n",
    "for session in test_sessions:\n",
    "    if session['purchased'] != []:\n",
    "        ptest_sessions.append(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Sorting viewed ids by popularity and by purchasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_by_popularity(sessions_data):\n",
    "    new_list = []\n",
    "    for session in sessions_data:\n",
    "        d = {}\n",
    "        ids = list(OrderedDict.fromkeys(session['viewed']))\n",
    "        d['viewed'] = sorted(ids, key=lambda x: viewed_counter[x], reverse=True) \n",
    "        d['purchased'] = session['purchased']\n",
    "        new_list.append(d)\n",
    "    return new_list\n",
    "    \n",
    "\n",
    "def sorting_by_purchasing(sessions_data):\n",
    "    new_list = []\n",
    "    for session in sessions_data:\n",
    "        d = {}\n",
    "        ids = list(OrderedDict.fromkeys(session['viewed']))\n",
    "        d['viewed'] = sorted(ids, key=lambda x: purchased_counter[x], reverse=True)\n",
    "        d['purchased'] = session['purchased']\n",
    "        new_list.append(d)\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptrain_popularity = sorting_by_popularity(ptrain_sessions)\n",
    "ptrain_purchasing = sorting_by_purchasing(ptrain_sessions)\n",
    "\n",
    "ptest_popularity = sorting_by_popularity(ptest_sessions)\n",
    "ptest_purchasing = sorting_by_purchasing(ptest_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Functions of precision@k and recall@k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_k(sessions_data, k):\n",
    "    precisions_list = []\n",
    "    for session in sessions_data:\n",
    "        i = 0\n",
    "        rec_ids = session['viewed'][:k]\n",
    "        pur_ids = session['purchased']\n",
    "        for rec in rec_ids:\n",
    "            for pur in pur_ids:\n",
    "                if rec == pur:\n",
    "                    i += 1\n",
    "        precisions_list.append(i/k)\n",
    "    return precisions_list\n",
    "\n",
    "def recall_k(sessions_data, k):\n",
    "    recalls_list = []\n",
    "    for session in sessions_data:\n",
    "        i = 0\n",
    "        rec_ids = session['viewed'][:k]\n",
    "        pur_ids = session['purchased']\n",
    "        for rec in rec_ids:\n",
    "            for pur in pur_ids:\n",
    "                if rec == pur:\n",
    "                    i +=1\n",
    "        recalls_list.append(i/len(pur_ids))\n",
    "    return recalls_list                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Calculating and writing answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: 0.44 0.51 0.82 0.21\n",
      "Answer 2: 0.42 0.48 0.8 0.2\n",
      "Answer 3: 0.69 0.8 0.93 0.25\n",
      "Answer 4: 0.46 0.53 0.82 0.21\n"
     ]
    }
   ],
   "source": [
    "def answer(data):\n",
    "    answer = []\n",
    "    for k in (1, 5):\n",
    "        rec = round(np.mean(recall_k(data, k)), 2)\n",
    "        answer.append(rec)\n",
    "        prec = round(np.mean(precision_k(data, k)), 2)\n",
    "        answer.append(prec)\n",
    "    return answer\n",
    "\n",
    "answer1 = answer(ptrain_popularity)\n",
    "print('Answer 1: ' + ' '.join(map(str, answer1)))\n",
    "with open('answer1.txt', 'w') as f:\n",
    "    f.write(' '.join(map(str, answer1)))\n",
    "    \n",
    "answer2 = answer(ptest_popularity)\n",
    "print('Answer 2: ' + ' '.join(map(str, answer2)))\n",
    "with open('answer2.txt', 'w') as f:\n",
    "    f.write(' '.join(map(str, answer2)))\n",
    "\n",
    "answer3 = answer(ptrain_purchasing)\n",
    "print('Answer 3: ' + ' '.join(map(str, answer3)))\n",
    "with open('answer3.txt', 'w') as f:\n",
    "    f.write(' '.join(map(str, answer3)))\n",
    "    \n",
    "answer4 = answer(ptest_purchasing)\n",
    "print('Answer 4: ' + ' '.join(map(str, answer4)))\n",
    "with open('answer4.txt', 'w') as f:\n",
    "    f.write(' '.join(map(str, answer4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
